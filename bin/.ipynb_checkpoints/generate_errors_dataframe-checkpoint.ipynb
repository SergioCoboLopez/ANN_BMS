{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddfa66ce-b426-4d15-a0e5-2ca3719dbff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "import ast\n",
    "import sys\n",
    "sys.path.append('machine-scientist/')\n",
    "sys.path.append('machine-scientist/Prior/')\n",
    "from mcmc import *\n",
    "from parallel import *\n",
    "from fit_prior import read_prior_par\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec1a2d5-59ef-4bf6-9810-13ed3cdc08c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_index(dataframe):\n",
    "    dataframe.set_index('Unnamed: 0', inplace=True)\n",
    "    dataframe.index.name = None\n",
    "    dataframe= dataframe.reset_index(drop=True)\n",
    "    return dataframe\n",
    "\n",
    "def add_bms_pred(dataframe, bms_trace, number_param):\n",
    "    VARS = ['x1',]\n",
    "    x = dn[[c for c in VARS]].copy()\n",
    "    y=dataframe.noise\n",
    "\n",
    "    if number_param==10:\n",
    "        prior_par = read_prior_par('machine-scientist/Prior/final_prior_param_sq.named_equations.nv1.np10.2017-10-18 18:07:35.089658.dat')\n",
    "    elif number_param==20:\n",
    "        prior_par = read_prior_par('machine-scientist/Prior/final_prior_param_sq.named_equations.nv1.np20.maxs200.2024-05-10 162907.551306.dat')\n",
    "\n",
    "    #mdl model\n",
    "    minrow = bms_trace[bms_trace.H == min(bms_trace.H)].iloc[0]\n",
    "    minH, minexpr, minparvals = minrow.H, minrow.expr, ast.literal_eval(minrow.parvals)\n",
    "\n",
    "    t = Tree(\n",
    "        variables=list(x.columns),\n",
    "        parameters=['a%d' % i for i in range(number_param)],\n",
    "        x=x, y=y,\n",
    "        prior_par=prior_par,\n",
    "        max_size=200,\n",
    "        from_string=minexpr,\n",
    "    )\n",
    "\n",
    "    t.set_par_values(deepcopy(minparvals))\n",
    "\n",
    "    dplot = deepcopy(dn)\n",
    "    dplot['ybms'] = t.predict(x)\n",
    "\n",
    "    return dplot\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad528c4e-9606-4902-bffe-64a9161b281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma\n",
      "0.0\n",
      "0\n",
      "0\n",
      "sigma\n",
      "0.0\n",
      "1\n",
      "0\n",
      "sigma\n",
      "0.0\n",
      "2\n",
      "0\n",
      "sigma\n",
      "0.0\n",
      "3\n",
      "0\n",
      "sigma\n",
      "0.0\n",
      "4\n",
      "0\n",
      "sigma\n",
      "0.0\n",
      "5\n",
      "0\n",
      "sigma\n",
      "0.0\n",
      "6\n",
      "0\n",
      "sigma\n",
      "0.0\n",
      "7\n",
      "0\n",
      "sigma\n",
      "0.0\n",
      "8\n",
      "0\n",
      "sigma\n",
      "0.0\n",
      "9\n",
      "0\n",
      "sigma\n",
      "0.0\n",
      "0\n",
      "1\n",
      "sigma\n",
      "0.0\n",
      "1\n",
      "1\n",
      "sigma\n",
      "0.0\n",
      "2\n",
      "1\n",
      "sigma\n",
      "0.0\n",
      "3\n",
      "1\n",
      "sigma\n",
      "0.0\n",
      "4\n",
      "1\n",
      "sigma\n",
      "0.0\n",
      "5\n",
      "1\n",
      "sigma\n",
      "0.0\n",
      "6\n",
      "1\n",
      "sigma\n",
      "0.0\n",
      "7\n",
      "1\n",
      "sigma\n",
      "0.0\n",
      "8\n",
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m mae_nn_test_i\u001b[38;5;241m=\u001b[39mmean_absolute_error(dplot\u001b[38;5;241m.\u001b[39mloc[train_size\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mymodel\u001b[39m\u001b[38;5;124m'\u001b[39m],dplot\u001b[38;5;241m.\u001b[39mloc[train_size \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     64\u001b[0m mae_nn_test\u001b[38;5;241m.\u001b[39mappend(mae_nn_test_i)\n\u001b[0;32m---> 66\u001b[0m rmse_mdl_i\u001b[38;5;241m=\u001b[39m\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mybms\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m rmse_mdl_train_i\u001b[38;5;241m=\u001b[39mroot_mean_squared_error(dplot\u001b[38;5;241m.\u001b[39mloc[:train_size\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mybms\u001b[39m\u001b[38;5;124m'\u001b[39m],dn\u001b[38;5;241m.\u001b[39mloc[:train_size\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     69\u001b[0m rmse_mdl_train\u001b[38;5;241m.\u001b[39mappend(rmse_mdl_train_i)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:506\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m    502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[1;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[1;32m    504\u001b[0m         )\n\u001b[0;32m--> 506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    510\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:112\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m--> 112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "#Read NN and BMS data\n",
    "function='tanh' #tanh, leaky_ReLU\n",
    "realizations=2\n",
    "N=9\n",
    "#sigmas=[sigma_y for sigma_y in np.arange(0,0.2,0.02)]\n",
    "sigmas=[0.0, 0.02, 0.04,0.06, 0.08, 0.10, 0.12, 0.14, 0.16, 0.18, 0.20]\n",
    "\n",
    "\n",
    "runid=0\n",
    "NPAR=10 #10, 20\n",
    "steps=50000\n",
    "train_size=60\n",
    "\n",
    "rmse_nn_train=[];rmse_nn_test=[]\n",
    "rmse_mdl_train=[];rmse_mdl_test=[]\n",
    "\n",
    "mae_nn_train=[];mae_nn_test=[]\n",
    "mae_mdl_train=[];mae_mdl_test=[]\n",
    "\n",
    "n_index=[];r_index=[];sigma_index=[]\n",
    "\n",
    "#Put mae and rmse of each simulation (on nn and bms) in a dataframe\n",
    "for sigma in sigmas:\n",
    "    for r in range(realizations+1):\n",
    "        #Read NN data\n",
    "        if sigma==0.1:\n",
    "            file_model='NN_no_overfit_' + function + '_sigma_' + '0.10' + '_r_' + str(r) + '.csv'\n",
    "        else:\n",
    "            file_model='NN_no_overfit_' + function + '_sigma_' + str(sigma) + '_r_' + str(r) + '.csv'\n",
    "            \n",
    "        model_d='../data/trained_nns/' + file_model\n",
    "        d=pd.read_csv(model_d)\n",
    "\n",
    "        for n in range(N+1):\n",
    "            print(\"sigma\")\n",
    "            print(sigma)\n",
    "            print(n)\n",
    "            print(r)\n",
    "            n_index.append(n);r_index.append(r);sigma_index.append(sigma)\n",
    "            \n",
    "            dn=d[d['rep']==n]\n",
    "            dn=clean_index(dn)\n",
    "\n",
    "            #Read BMS data\n",
    "            if sigma==0.1:\n",
    "                filename='BMS_'+function+'_n_'+str(n)+'_sigma_'+'0.10'+ '_r_' + str(r) + '_trace_'+str(steps)+'_prior_'+str(NPAR)+ '.csv'\n",
    "            else:\n",
    "                filename='BMS_'+function+'_n_'+str(n)+'_sigma_'+str(sigma)+ '_r_' + str(r) + '_trace_'+str(steps)+'_prior_'+str(NPAR)+ '.csv'\n",
    "        \n",
    "            trace=pd.read_csv('../data/MSTraces/' + filename, sep=';', header=None, names=['t', 'H', 'expr', 'parvals', 'kk1', 'kk2','kk3'])\n",
    "            dplot=add_bms_pred(dn, trace, NPAR)\n",
    "\n",
    "            #Errors\n",
    "            rmse_nn_train_i=root_mean_squared_error(dplot.loc[:train_size-1]['ymodel'],dplot.loc[:train_size -1]['y'])\n",
    "            rmse_nn_train.append(rmse_nn_train_i)\n",
    "            \n",
    "            rmse_nn_test_i=root_mean_squared_error(dplot.loc[train_size-1:]['ymodel'],dplot.loc[train_size -1:]['y'])\n",
    "            rmse_nn_test.append(rmse_nn_test_i)\n",
    "\n",
    "            mae_nn_train_i=mean_absolute_error(dplot.loc[:train_size-1]['ymodel'],dplot.loc[:train_size -1]['y'])\n",
    "            mae_nn_train.append(mae_nn_train_i)\n",
    "            \n",
    "            mae_nn_test_i=mean_absolute_error(dplot.loc[train_size-1:]['ymodel'],dplot.loc[train_size -1:]['y'])\n",
    "            mae_nn_test.append(mae_nn_test_i)\n",
    "    \n",
    "            rmse_mdl_i=mean_squared_error(dplot.ybms,dn.y)\n",
    "            \n",
    "            rmse_mdl_train_i=root_mean_squared_error(dplot.loc[:train_size-1]['ybms'],dn.loc[:train_size-1]['y'])\n",
    "            rmse_mdl_train.append(rmse_mdl_train_i)\n",
    "            \n",
    "            rmse_mdl_test_i=root_mean_squared_error(dplot.loc[train_size-1:]['ybms'],dn.loc[train_size-1:]['y'])\n",
    "            rmse_mdl_test.append(rmse_mdl_test_i)\n",
    "\n",
    "            mae_mdl_train_i=mean_absolute_error(dplot.loc[:train_size-1]['ybms'],dplot.loc[:train_size -1]['y'])\n",
    "            mae_mdl_train.append(mae_mdl_train_i)\n",
    "            \n",
    "            mae_mdl_test_i=mean_absolute_error(dplot.loc[train_size-1:]['ybms'],dplot.loc[train_size -1:]['y'])\n",
    "            mae_mdl_test.append(mae_mdl_test_i)\n",
    "\n",
    "errors_df=pd.DataFrame({'sigma':sigma_index, 'mae_nn_train':mae_nn_train, 'mae_nn_test':mae_nn_test, 'mae_mdl_train':mae_mdl_train, \n",
    "                        'mae_mdl_test':mae_mdl_test, 'rmse_nn_train':rmse_nn_train, 'rmse_nn_test': rmse_nn_test, \n",
    "                        'rmse_mdl_train':rmse_mdl_train, 'rmse_mdl_test': rmse_mdl_test, 'n':n_index, 'r': r_index})\n",
    "display(errors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695e11af-8dd9-4a88-8089-73338ba81106",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_errors=['mae_nn_train','mae_nn_test','mae_mdl_train','mae_mdl_test','rmse_nn_train','rmse_nn_test','rmse_mdl_train','rmse_mdl_test']\n",
    "\n",
    "#Mean values of 30 (3*10) simulations\n",
    "mean_errors_df=errors_df.groupby(['sigma'],as_index=False)[columns_errors].mean()\n",
    "#display(mean_errors_df)\n",
    "\n",
    "\n",
    "#Error\n",
    "#1. For every sigma and every n, calculate means over the realizations\n",
    "mean_n_over_r_df=errors_df.groupby(['n', 'sigma'],as_index=False)[columns_errors].mean()\n",
    "#display(mean_n_over_r_df)\n",
    "\n",
    "#2. Calculate stds over means of over realizations\n",
    "std_n_over_r_df=mean_n_over_r_df.groupby(['sigma'],as_index=False)[columns_errors].std() \n",
    "\n",
    "#rename columns\n",
    "std_n_over_r_df=std_n_over_r_df.rename(columns={column:'std_' + column for column in columns_errors})\n",
    "display(std_n_over_r_df)\n",
    "\n",
    "\n",
    "#3. sem: divide by sqare root of realizations\n",
    "std_n_over_r_df[['sem_mae_nn_train','sem_mae_nn_test','sem_mae_mdl_train','sem_mae_mdl_test',\\\n",
    "                 'sem_rmse_nn_train','sem_rmse_nn_test','sem_rmse_mdl_train','sem_rmse_mdl_test' ]]=\\\n",
    "std_n_over_r_df[['std_mae_nn_train', 'std_mae_nn_test', 'std_mae_mdl_train', 'std_mae_mdl_test', 'std_rmse_nn_train',\\\n",
    "                 'std_rmse_nn_test','std_rmse_mdl_train','std_rmse_mdl_test' ]]/np.sqrt(realizations+1)\n",
    "\n",
    "#sem_n_over_r_df=std_n_over_r_df[columns_errors]/np.sqrt(realizations+1)\n",
    "display(std_n_over_r_df)\n",
    "\n",
    "#rename columns\n",
    "std_n_over_r_df=std_n_over_r_df.rename(columns={'mae_nn_train':  'std_mae_nn_train',  'mae_nn_test':  'std_mae_nn_test', \n",
    "                                            'mae_mdl_train': 'std_mae_mdl_train', 'mae_mdl_test': 'std_mae_mdl_test',\n",
    "                                            'rmse_nn_train': 'std_rmse_nn_train', 'rmse_nn_test': 'std_rmse_nn_test' , \n",
    "                                            'rmse_mdl_train':'std_rmse_mdl_train','rmse_mdl_test':'std_rmse_mdl_test'})\n",
    "\n",
    "\n",
    "#sem_n_over_r_df=sem_n_over_r_df.rename(columns={'mae_nn_train':  'sem_mae_nn_train',  'mae_nn_test':  'sem_mae_nn_test', \n",
    "#                                            'mae_mdl_train': 'sem_mae_mdl_train', 'sem_mae_mdl_test': 'sem_mae_mdl_test',\n",
    "#                                            'rmse_nn_train': 'sem_rmse_nn_train', 'sem_rmse_nn_test': 'sem_rmse_nn_test' , \n",
    "#                                            'rmse_mdl_train':'sem_rmse_mdl_train','sem_rmse_mdl_test':'sem_rmse_mdl_test'})\n",
    "\n",
    "\n",
    "errors_statistics_new=mean_errors_df.join(std_n_over_r_df.set_index('sigma'), on='sigma')\n",
    "display(errors_statistics_new)\n",
    "\n",
    "print('../data/errors_statistics_' + str(function) + '.csv')\n",
    "errors_statistics_new.to_csv('../data/errors_statistics_' + str(function) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3faba38e-6d95-4c98-acfe-ffaea47d2b9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2887671460.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    for col in range(len(cols)):\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "##INCOMPLETE!!\n",
    "\n",
    "#Plot rmse\n",
    "Extensions=['.png', '.pdf']\n",
    "\n",
    "#Fonts and sizes                                                                                    \n",
    "size_axis=7;size_ticks=6;size_title=5\n",
    "line_w=1;marker_s=3 #width and marker size                                                          \n",
    "m_size=6\n",
    "\n",
    "#Define figure size in cm                                                                           \n",
    "cm = 1/2.54 #convert inch to cm                                                                     \n",
    "width = 8*cm; height=6*cm\n",
    "rows=3;cols=10\n",
    "\n",
    "width_panel = width*cols\n",
    "height_panel= height*rows\n",
    "\n",
    "fig=figure(figsize=(width_panel,height_panel), dpi=300)  \n",
    "gs=gridspec.GridSpec(rows,cols)                                                                                                                         \n",
    "gs.update(left=0.1,right=0.98,bottom=0.15,top=0.90,wspace=0.35,hspace=0.1) \n",
    "\n",
    "for row in range(len(rows)):\n",
    "    print(row)\n",
    "    for col in range(len(cols)): \n",
    "        print(col)\n",
    "\n",
    "        ax_ij=plt.subplot(gs[i,j])\n",
    "        plt.plot(dn['x1'], dn['ymodel'],linewidth=line_w, color='red', label='ann.  MSE_train= %.2E, MSE_test= %.2E' % ( MAE_nn_train, MAE_nn_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68929ff9-cc1d-4b54-9808-b2afb2c61e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
